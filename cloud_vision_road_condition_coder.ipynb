{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu4KDxtPk9ikVrPYkOUyEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geosensing/streetsense2/blob/main/cloud_vision_road_condition_coder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import requests\n",
        "import io\n",
        "import base64\n",
        "\n",
        "class CloudVisionTokenAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes street conditions from Street View images using Google Cloud Vision API with API token.\n",
        "    Focuses on potholes, garbage, and overall street condition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key=None):\n",
        "        \"\"\"\n",
        "        Initialize the Cloud Vision API Analyzer.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): Google Cloud API key\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.api_url = \"https://vision.googleapis.com/v1/images:annotate\"\n",
        "\n",
        "        # Define which labels might indicate problems\n",
        "        self.pothole_keywords = [\n",
        "            'pothole', 'hole', 'crack', 'cracked', 'damaged', 'damage',\n",
        "            'broken', 'asphalt damage', 'road damage', 'pavement damage'\n",
        "        ]\n",
        "\n",
        "        self.garbage_keywords = [\n",
        "            'garbage', 'trash', 'litter', 'waste', 'rubbish', 'debris',\n",
        "            'bottle', 'can', 'plastic', 'paper', 'bag', 'junk'\n",
        "        ]\n",
        "\n",
        "        print(\"Initialized Cloud Vision Token Analyzer\")\n",
        "\n",
        "    def analyze_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Analyze a single street view image using Cloud Vision API.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to the image file\n",
        "\n",
        "        Returns:\n",
        "            dict: Analysis results containing detected issues\n",
        "        \"\"\"\n",
        "        if not self.api_key:\n",
        "            return {\"error\": \"API key not provided\"}\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            return {\"error\": f\"Image file not found: {image_path}\"}\n",
        "\n",
        "        try:\n",
        "            # Read and encode image\n",
        "            with open(image_path, 'rb') as image_file:\n",
        "                encoded_image = base64.b64encode(image_file.read()).decode('UTF-8')\n",
        "\n",
        "            # Create request payload\n",
        "            request_json = {\n",
        "                \"requests\": [\n",
        "                    {\n",
        "                        \"image\": {\n",
        "                            \"content\": encoded_image\n",
        "                        },\n",
        "                        \"features\": [\n",
        "                            {\"type\": \"LABEL_DETECTION\", \"maxResults\": 20},\n",
        "                            {\"type\": \"OBJECT_LOCALIZATION\", \"maxResults\": 20}\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            # Make API request\n",
        "            response = requests.post(\n",
        "                f\"{self.api_url}?key={self.api_key}\",\n",
        "                json=request_json\n",
        "            )\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                return {\"error\": f\"API Error: {response.status_code} - {response.text}\"}\n",
        "\n",
        "            # Parse response\n",
        "            api_response = response.json()[\"responses\"][0]\n",
        "\n",
        "            # Extract annotations\n",
        "            labels = api_response.get(\"labelAnnotations\", [])\n",
        "            objects = api_response.get(\"localizedObjectAnnotations\", [])\n",
        "\n",
        "            # Analyze the annotations\n",
        "            results = {\n",
        "                \"image_path\": image_path,\n",
        "                \"has_road\": self._check_if_road(labels, objects),\n",
        "                \"potholes\": self._detect_potholes(labels, objects),\n",
        "                \"garbage\": self._detect_garbage(labels, objects),\n",
        "                \"raw_labels\": [{\"description\": label.get(\"description\", \"\"), \"score\": label.get(\"score\", 0)} for label in labels],\n",
        "                \"raw_objects\": [{\"name\": obj.get(\"name\", \"\"), \"score\": obj.get(\"score\", 0)} for obj in objects]\n",
        "            }\n",
        "\n",
        "            # Calculate overall street condition score\n",
        "            self._calculate_overall_condition(results)\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Error analyzing image with Cloud Vision: {str(e)}\"}\n",
        "\n",
        "    def _check_if_road(self, labels, objects):\n",
        "        \"\"\"Check if the image contains a road.\"\"\"\n",
        "        road_keywords = ['road', 'street', 'highway', 'lane', 'asphalt', 'pavement']\n",
        "\n",
        "        # Check labels for road-related terms\n",
        "        for label in labels:\n",
        "            if any(keyword in label.get(\"description\", \"\").lower() for keyword in road_keywords):\n",
        "                return True\n",
        "\n",
        "        # Check objects for road-related objects\n",
        "        for obj in objects:\n",
        "            if any(keyword in obj.get(\"name\", \"\").lower() for keyword in road_keywords):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _detect_potholes(self, labels, objects):\n",
        "        \"\"\"\n",
        "        Detect potholes in the image using Cloud Vision annotations.\n",
        "\n",
        "        Args:\n",
        "            labels: Label annotations from Cloud Vision\n",
        "            objects: Object localization annotations from Cloud Vision\n",
        "\n",
        "        Returns:\n",
        "            dict: Pothole detection results\n",
        "        \"\"\"\n",
        "        # Look for pothole keywords in labels\n",
        "        pothole_scores = []\n",
        "        for label in labels:\n",
        "            if any(keyword in label.get(\"description\", \"\").lower() for keyword in self.pothole_keywords):\n",
        "                pothole_scores.append(label.get(\"score\", 0))\n",
        "\n",
        "        # Calculate severity based on scores\n",
        "        if len(pothole_scores) > 0:\n",
        "            max_score = max(pothole_scores)\n",
        "\n",
        "            # Determine severity (0-3)\n",
        "            severity = 0\n",
        "            if max_score < 0.6:\n",
        "                severity = 1  # Low confidence\n",
        "            elif max_score < 0.8:\n",
        "                severity = 2  # Medium confidence\n",
        "            else:\n",
        "                severity = 3  # High confidence\n",
        "\n",
        "            count = len(pothole_scores)\n",
        "\n",
        "            return {\n",
        "                \"count\": count,\n",
        "                \"severity\": severity,\n",
        "                \"confidence\": max_score\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"count\": 0,\n",
        "                \"severity\": 0,\n",
        "                \"confidence\": 0\n",
        "            }\n",
        "\n",
        "    def _detect_garbage(self, labels, objects):\n",
        "        \"\"\"\n",
        "        Detect garbage in the image using Cloud Vision annotations.\n",
        "\n",
        "        Args:\n",
        "            labels: Label annotations from Cloud Vision\n",
        "            objects: Object localization annotations from Cloud Vision\n",
        "\n",
        "        Returns:\n",
        "            dict: Garbage detection results\n",
        "        \"\"\"\n",
        "        # Look for garbage keywords in labels\n",
        "        garbage_scores = []\n",
        "        for label in labels:\n",
        "            if any(keyword in label.get(\"description\", \"\").lower() for keyword in self.garbage_keywords):\n",
        "                garbage_scores.append(label.get(\"score\", 0))\n",
        "\n",
        "        # Look for garbage objects\n",
        "        garbage_objects = []\n",
        "        for obj in objects:\n",
        "            if any(keyword in obj.get(\"name\", \"\").lower() for keyword in self.garbage_keywords):\n",
        "                garbage_objects.append({\n",
        "                    \"name\": obj.get(\"name\", \"\"),\n",
        "                    \"score\": obj.get(\"score\", 0)\n",
        "                })\n",
        "\n",
        "        # Calculate severity based on scores and count\n",
        "        if len(garbage_scores) > 0 or len(garbage_objects) > 0:\n",
        "            # Combine scores from labels and objects\n",
        "            all_scores = garbage_scores + [obj[\"score\"] for obj in garbage_objects]\n",
        "            max_score = max(all_scores) if all_scores else 0\n",
        "\n",
        "            # Determine count and severity (0-3)\n",
        "            count = len(garbage_objects) if garbage_objects else len(garbage_scores)\n",
        "\n",
        "            severity = 0\n",
        "            if count == 0:\n",
        "                severity = 0\n",
        "            elif count < 3:\n",
        "                severity = 1  # Minor litter\n",
        "            elif count < 6:\n",
        "                severity = 2  # Moderate litter\n",
        "            else:\n",
        "                severity = 3  # Severe litter\n",
        "\n",
        "            return {\n",
        "                \"count\": count,\n",
        "                \"severity\": severity,\n",
        "                \"confidence\": max_score\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"count\": 0,\n",
        "                \"severity\": 0,\n",
        "                \"confidence\": 0\n",
        "            }\n",
        "\n",
        "    def _calculate_overall_condition(self, results):\n",
        "        \"\"\"\n",
        "        Calculate overall street condition score.\n",
        "\n",
        "        Args:\n",
        "            results (dict): Analysis results with individual conditions\n",
        "\n",
        "        Returns:\n",
        "            None: Updates results dict in-place\n",
        "        \"\"\"\n",
        "        # If there's no road in the image, can't properly assess\n",
        "        if not results[\"has_road\"]:\n",
        "            results[\"overall_condition\"] = {\n",
        "                \"score\": None,\n",
        "                \"rating\": \"Not applicable - No road detected\"\n",
        "            }\n",
        "            return\n",
        "\n",
        "        # Start with a perfect score and subtract based on issues\n",
        "        score = 10.0\n",
        "\n",
        "        # Subtract for potholes (0-5 points)\n",
        "        pothole_severity = results[\"potholes\"][\"severity\"]\n",
        "        if pothole_severity == 1:\n",
        "            score -= 1\n",
        "        elif pothole_severity == 2:\n",
        "            score -= 3\n",
        "        elif pothole_severity == 3:\n",
        "            score -= 5\n",
        "\n",
        "        # Subtract for garbage (0-3 points)\n",
        "        garbage_severity = results[\"garbage\"][\"severity\"]\n",
        "        if garbage_severity == 1:\n",
        "            score -= 0.5\n",
        "        elif garbage_severity == 2:\n",
        "            score -= 1.5\n",
        "        elif garbage_severity == 3:\n",
        "            score -= 3\n",
        "\n",
        "        # Ensure score is in range 0-10\n",
        "        score = max(0, min(10, score))\n",
        "\n",
        "        # Assign a rating\n",
        "        if score >= 9:\n",
        "            rating = \"Excellent\"\n",
        "        elif score >= 7:\n",
        "            rating = \"Good\"\n",
        "        elif score >= 5:\n",
        "            rating = \"Fair\"\n",
        "        elif score >= 3:\n",
        "            rating = \"Poor\"\n",
        "        else:\n",
        "            rating = \"Very Poor\"\n",
        "\n",
        "        results[\"overall_condition\"] = {\n",
        "            \"score\": score,\n",
        "            \"rating\": rating\n",
        "        }\n",
        "\n",
        "    def analyze_directory(self, images_dir, output_csv=None):\n",
        "        \"\"\"\n",
        "        Analyze all images in a directory and output results to CSV.\n",
        "\n",
        "        Args:\n",
        "            images_dir (str): Directory containing images\n",
        "            output_csv (str): Path to save CSV results\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Analysis results for all images\n",
        "        \"\"\"\n",
        "        if not self.api_key:\n",
        "            print(\"Error: API key not provided\")\n",
        "            return None\n",
        "\n",
        "        if not os.path.exists(images_dir):\n",
        "            print(f\"Error: Directory not found: {images_dir}\")\n",
        "            return None\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        if output_csv:\n",
        "            output_dir = os.path.dirname(output_csv)\n",
        "            if output_dir and not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "\n",
        "        # Find all image files\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "        image_files = []\n",
        "\n",
        "        for root, _, files in os.walk(images_dir):\n",
        "            for file in files:\n",
        "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                    image_files.append(os.path.join(root, file))\n",
        "\n",
        "        print(f\"Found {len(image_files)} images to analyze\")\n",
        "\n",
        "        all_results = []\n",
        "\n",
        "        # Process each image\n",
        "        for image_file in tqdm(image_files, desc=\"Analyzing images with Cloud Vision\"):\n",
        "            # Analyze image\n",
        "            results = self.analyze_image(image_file)\n",
        "\n",
        "            if \"error\" not in results:\n",
        "                # Create summary for DataFrame with only pothole, garbage and overall ratings\n",
        "                summary = {\n",
        "                    \"image_path\": image_file,\n",
        "                    \"has_road\": results.get(\"has_road\", False),\n",
        "                    \"pothole_count\": results[\"potholes\"].get(\"count\", 0),\n",
        "                    \"pothole_severity\": results[\"potholes\"].get(\"severity\", 0),\n",
        "                    \"pothole_confidence\": results[\"potholes\"].get(\"confidence\", 0),\n",
        "                    \"garbage_count\": results[\"garbage\"].get(\"count\", 0),\n",
        "                    \"garbage_severity\": results[\"garbage\"].get(\"severity\", 0),\n",
        "                    \"garbage_confidence\": results[\"garbage\"].get(\"confidence\", 0),\n",
        "                    \"overall_score\": results.get(\"overall_condition\", {}).get(\"score\"),\n",
        "                    \"overall_rating\": results.get(\"overall_condition\", {}).get(\"rating\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "                all_results.append(summary)\n",
        "            else:\n",
        "                print(f\"Error analyzing {image_file}: {results['error']}\")\n",
        "\n",
        "        # Convert results to DataFrame\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "\n",
        "        # Save results to CSV if path is provided\n",
        "        if output_csv:\n",
        "            results_df.to_csv(output_csv, index=False)\n",
        "            print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def generate_summary_charts(self, results_df, output_dir):\n",
        "        \"\"\"\n",
        "        Generate summary charts based on the analysis results.\n",
        "\n",
        "        Args:\n",
        "            results_df (pd.DataFrame): Analysis results\n",
        "            output_dir (str): Directory to save charts\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        if results_df is None or results_df.empty:\n",
        "            print(\"No data to generate charts\")\n",
        "            return\n",
        "\n",
        "        # Filter only images with roads\n",
        "        road_df = results_df[results_df['has_road'] == True].copy()\n",
        "\n",
        "        if road_df.empty:\n",
        "            print(\"No road images found in the analysis\")\n",
        "            return\n",
        "\n",
        "        # 1. Overall condition distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        condition_counts = road_df['overall_rating'].value_counts().sort_index()\n",
        "        condition_counts.plot(kind='bar', color='skyblue')\n",
        "        plt.title('Street Condition Distribution')\n",
        "        plt.xlabel('Condition Rating')\n",
        "        plt.ylabel('Number of Images')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'condition_distribution.png'))\n",
        "        plt.close()\n",
        "\n",
        "        # 2. Pothole severity distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        pothole_severity = road_df['pothole_severity'].value_counts().sort_index()\n",
        "        pothole_severity.plot(kind='bar', color='tomato')\n",
        "        plt.title('Pothole Severity Distribution')\n",
        "        plt.xlabel('Severity Level (0-3)')\n",
        "        plt.ylabel('Number of Images')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'pothole_severity.png'))\n",
        "        plt.close()\n",
        "\n",
        "        # 3. Garbage severity distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        garbage_severity = road_df['garbage_severity'].value_counts().sort_index()\n",
        "        garbage_severity.plot(kind='bar', color='olivedrab')\n",
        "        plt.title('Garbage Severity Distribution')\n",
        "        plt.xlabel('Severity Level (0-3)')\n",
        "        plt.ylabel('Number of Images')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'garbage_severity.png'))\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"Charts saved to {output_dir}\")\n",
        "\n",
        "\n",
        "# Main function to process all images in a directory\n",
        "def analyze_street_images(api_key, images_dir, output_csv=None, generate_charts=False, charts_dir=None):\n",
        "    \"\"\"\n",
        "    Process all street view images in a directory using Google Cloud Vision API\n",
        "    and output pothole, garbage and overall ratings to CSV.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Google Cloud API key\n",
        "        images_dir (str): Directory containing street view images\n",
        "        output_csv (str): Path to save CSV results\n",
        "        generate_charts (bool): Whether to generate summary charts\n",
        "        charts_dir (str): Directory to save charts if generated\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Analysis results\n",
        "    \"\"\"\n",
        "    # Initialize the analyzer\n",
        "    analyzer = CloudVisionTokenAnalyzer(api_key=api_key)\n",
        "\n",
        "    # Analyze all images\n",
        "    results_df = analyzer.analyze_directory(images_dir, output_csv)\n",
        "\n",
        "    # Generate charts if requested\n",
        "    if generate_charts and charts_dir and results_df is not None and not results_df.empty:\n",
        "        analyzer.generate_summary_charts(results_df, charts_dir)\n",
        "\n",
        "    # Print summary statistics\n",
        "    if results_df is not None and not results_df.empty:\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(f\"Total images analyzed: {len(results_df)}\")\n",
        "        print(f\"Images with road visible: {results_df['has_road'].sum()} ({results_df['has_road'].mean()*100:.1f}%)\")\n",
        "\n",
        "        # Filter for images with roads\n",
        "        road_df = results_df[results_df['has_road'] == True]\n",
        "\n",
        "        if not road_df.empty:\n",
        "            print(f\"Images with potholes: {(road_df['pothole_count'] > 0).sum()} ({(road_df['pothole_count'] > 0).mean()*100:.1f}%)\")\n",
        "            print(f\"Images with garbage: {(road_df['garbage_count'] > 0).sum()} ({(road_df['garbage_count'] > 0).mean()*100:.1f}%)\")\n",
        "            print(f\"Average condition score: {road_df['overall_score'].mean():.2f}/10\")\n",
        "\n",
        "            # Print condition distribution\n",
        "            print(\"\\nStreet Condition Distribution:\")\n",
        "            condition_counts = road_df['overall_rating'].value_counts()\n",
        "            for rating, count in condition_counts.items():\n",
        "                print(f\"{rating}: {count} ({count/len(road_df)*100:.1f}%)\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Insert your Google Cloud API key here\n",
        "    API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "    # Directory containing Street View images\n",
        "    IMAGES_DIR = \"street_view_images\"\n",
        "\n",
        "    # Output CSV file path\n",
        "    OUTPUT_CSV = \"street_condition_results.csv\"\n",
        "\n",
        "    # Generate charts\n",
        "    GENERATE_CHARTS = True\n",
        "    CHARTS_DIR = \"condition_charts\"\n",
        "\n",
        "    # Run the analysis\n",
        "    results = analyze_street_images(API_KEY, IMAGES_DIR, OUTPUT_CSV, GENERATE_CHARTS, CHARTS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u039DkFjd-Sz",
        "outputId": "99c1d4ce-f878-4eed-dce7-612baaab7149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Cloud Vision Token Analyzer\n",
            "Found 6010 images to analyze\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing images with Cloud Vision:  18%|█▊        | 1068/6010 [11:26<59:21,  1.39it/s]"
          ]
        }
      ]
    }
  ]
}